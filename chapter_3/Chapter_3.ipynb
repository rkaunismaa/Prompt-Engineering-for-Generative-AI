{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturday, December 14, 2024\n",
    "\n",
    "This notebook was not part of the original authors repository, but was created from the sample code from Chapter 3.\n",
    "\n",
    "I'm really kinda surprised the authors repository didn't include a notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set your OpenAI key as an environment variable\n",
    "# https://platform.openai.com/api-keys\n",
    "# client = OpenAI(\n",
    "#   api_key=os.environ['OPENAI_API_KEY'],  # Default\n",
    "# )\n",
    "\n",
    "# Point to the local server ... last guy wins.\n",
    "# lmstudio = \"http://localhost:1234/v1\"\n",
    "lmstudio = \"http://192.168.2.16:1234/v1\"\n",
    "\n",
    "client = OpenAI(base_url=lmstudio, api_key=\"lm-studio\")\n",
    "\n",
    "model = \"qwen2.5-14b-instruct\" # lmstudio-community/Qwen2.5-14B-Instruct-GGUF : wen2.5-14B-Instruct-Q8_0.gguf\n",
    "\n",
    "# model = \"hermes-3-llama-3.2-3b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        model = model ,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Generate a list of Disney characters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a diverse list of popular Disney characters from various movies and shows:\n",
      "\n",
      "1. Mickey Mouse (Steamboat Willie)\n",
      "2. Minnie Mouse (Steamboat Willie)\n",
      "3. Donald Duck (The Wise Little Hen)\n",
      "4. Daisy Duck (Don Donald)\n",
      "5. Goofy (Mickey's Revue)\n",
      "6. Pluto (Pluto's Judgement Day)\n",
      "7. Scrooge McDuck (Christmas on Bear Mountain, Christmas at Willow Bay)\n",
      "8. Jiminy Cricket (Pinocchio)\n",
      "9. Dopey (Snow White and the Seven Dwarfs)\n",
      "10. Snow White (Snow White and the Seven Dwarfs)\n",
      "11. Cinderella (Cinderella)\n",
      "12. Aurora / Sleeping Beauty (Sleeping Beauty)\n",
      "13. Belle (Beauty and the Beast)\n",
      "14. Jasmine (Aladdin)\n",
      "15. Pocahontas (Pocahontas)\n",
      "16. Mulan (Mulan)\n",
      "17. Tiana (The Princess and the Frog)\n",
      "18. Rapunzel (Tangled)\n",
      "19. Merida (Brave)\n",
      "20. Moana (Moana)\n",
      "\n",
      "Animated Movie Characters:\n",
      "1. Simba, Nala, Pumbaa, Timon, Rafiki (The Lion King)\n",
      "2. Stitch (Lilo & Stitch)\n",
      "3. Buzz Lightyear and Woody (Toy Story series)\n",
      "4. Sully and Mike Wazowski (Monsters, Inc.)\n",
      "5. Baloo, Mowgli (The Jungle Book)\n",
      "6. Nemo and Marlin (Finding Nemo)\n",
      "\n",
      "Live-Action Movie Characters:\n",
      "1. Alice (Alice in Wonderland)\n",
      "2. Maleficent (Sleeping Beauty / Maleficent)\n",
      "3. Aladdin (Aladdin)\n",
      "4. Jasmine (Aladdin)\n",
      "5. Cruella de Vil (101 Dalmatians)\n",
      "\n",
      "Disney Channel and Disney Junior TV Show Characters:\n",
      "1. Doc McStuffins (Doc McStuffins)\n",
      "2. Elena of Avalor (Elena of Avalor)\n",
      "3. Jessie (Jessie)\n",
      "4. Mira Nova (Star vs the Forces of Evil)\n",
      "5. Baymax (Big Hero 6: The Series)\n",
      "\n",
      "This list is not exhaustive, but it covers some well-known and loved Disney characters from different eras and mediums.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 18.5s\n",
    "# 17.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response is unpredictable because we were not clear about the type of list we wanted. Let's try again, this time being more specific with what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Generate a bullet point list of 5 male Disney characters. \n",
    "Only include the name of the character for each line. \n",
    "Never include the film for each Disney character.\n",
    "\n",
    "Below is an example list:\n",
    "* Aladdin\n",
    "* Simba\n",
    "* Beast\n",
    "* Hercules\n",
    "* Tarzan\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Peter Pan\n",
      "* Genie\n",
      "* Woody\n",
      "* Mowgli\n",
      "* Stitch\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 0.9s\n",
    "# 0.7s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to observe just how much faster this prompt runs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical List Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical lists are useful for when your desired output is nested. A good example of this would be a detailed article structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Generate a hierarchical and incredibly detailed article outline on \"what are the benefits of data engineering\".\n",
    "\n",
    "See an example of the hierarchical structure below:\n",
    "\n",
    "Article Title: What are the benefits of digital marketing?\n",
    "\n",
    "* Introduction\n",
    "    a. Explanation of digital marketing\n",
    "    b. Importance of digital marketing in today’s business world\n",
    "\n",
    "* Increased Brand Awareness\n",
    "    a. Definition of brand awareness\n",
    "    b. How digital marketing helps in increasing brand awareness\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Article Title: What Are the Benefits of Data Engineering?\n",
      "\n",
      "#### I. Introduction\n",
      "   - A. Explanation of data engineering\n",
      "       1. Definition and scope of data engineering\n",
      "       2. Evolution of data engineering\n",
      "   - B. Importance of data engineering in today’s business world\n",
      "       1. Role in modern business operations\n",
      "       2. Impact on decision-making processes\n",
      "\n",
      "#### II. Enhanced Data Management Capabilities\n",
      "   - A. Efficient Data Collection and Integration\n",
      "       1. Automation of data ingestion from various sources\n",
      "       2. Standardization and normalization of diverse datasets\n",
      "   - B. Scalability and Flexibility\n",
      "       1. Adapting to growing data volumes and changing business needs\n",
      "       2. Elastic computing resources for optimal performance\n",
      "\n",
      "#### III. Improved Data Quality and Reliability\n",
      "   - A. Data Cleaning and Validation Techniques\n",
      "       1. Identifying and removing inconsistencies or inaccuracies\n",
      "       2. Implementing robust validation rules\n",
      "   - B. Ensuring Consistency Across Datasets\n",
      "       1. Uniform data formats across different systems\n",
      "       2. Maintaining referential integrity\n",
      "\n",
      "#### IV. Real-Time Data Processing for Immediate Insights\n",
      "   - A. Implementation of Stream Processing Technologies\n",
      "       1. Utilizing Apache Kafka and Apache Flink for real-time analytics\n",
      "       2. Benefits of immediate insights in business operations\n",
      "   - B. Enhancing Customer Experience through Real-Time Personalization\n",
      "       1. Dynamic content delivery based on user behavior\n",
      "       2. Immediate feedback mechanisms\n",
      "\n",
      "#### V. Advanced Analytics and Predictive Modeling\n",
      "   - A. Leveraging Data Warehousing Solutions\n",
      "       1. Efficient storage of large datasets for complex queries\n",
      "       2. Support for BI tools and advanced analytics\n",
      "   - B. Facilitating Machine Learning Pipelines\n",
      "       1. Preparing structured data sets for ML algorithms\n",
      "       2. Integration with cloud-based ML platforms like AWS Sagemaker\n",
      "\n",
      "#### VI. Cost Efficiency Through Optimization\n",
      "   - A. Reducing Storage Costs via Data Compression Techniques\n",
      "       1. Implementing efficient storage methods (e.g., Parquet, ORC)\n",
      "       2. Dynamic tiering of data based on usage patterns\n",
      "   - B. Minimizing Processing Time and Resource Usage\n",
      "       1. Utilization of distributed computing frameworks like Apache Spark\n",
      "       2. Efficient resource allocation strategies\n",
      "\n",
      "#### VII. Enhanced Security Measures\n",
      "   - A. Robust Data Encryption Methods\n",
      "       1. Implementing end-to-end encryption protocols\n",
      "       2. Compliance with regulatory standards (e.g., GDPR, HIPAA)\n",
      "   - B. Access Control and User Authentication Mechanisms\n",
      "       1. Role-based access control (RBAC) systems\n",
      "       2. Multi-factor authentication for secure data access\n",
      "\n",
      "#### VIII. Improved Decision-Making Processes\n",
      "   - A. Real-Time Monitoring and Alert Systems\n",
      "       1. Implementing anomaly detection algorithms\n",
      "       2. Automated alert mechanisms for critical events\n",
      "   - B. Data-Driven Strategic Planning\n",
      "       1. Utilizing insights from historical data to inform future strategies\n",
      "       2. Forecasting trends and predicting market movements\n",
      "\n",
      "#### IX. Streamlined Operations Through Automation\n",
      "   - A. Workflow Automation in ETL Processes\n",
      "       1. Automating extraction, transformation, and loading tasks\n",
      "       2. Reducing manual intervention and minimizing errors\n",
      "   - B. Continuous Integration/Continuous Deployment (CI/CD) for Data Pipelines\n",
      "       1. Ensuring seamless updates to data workflows\n",
      "       2. Monitoring system performance and reliability\n",
      "\n",
      "#### X. Competitive Advantage in the Market\n",
      "   - A. Leveraging Advanced Analytics for Business Growth\n",
      "       1. Identifying new market opportunities through data analysis\n",
      "       2. Enhancing product development with customer insights\n",
      "   - B. Differentiation from Competitors Through Data-Driven Innovations\n",
      "       1. Creating unique value propositions based on data-driven strategies\n",
      "       2. Implementing advanced technologies (AI, IoT) to stay ahead\n",
      "\n",
      "#### XI. Conclusion\n",
      "   - A. Recap of Key Benefits of Data Engineering\n",
      "       1. Summarizing the main advantages discussed in the article\n",
      "       2. Highlighting the transformative impact on business operations\n",
      "   - B. Future Outlook and Emerging Trends\n",
      "       1. Potential advancements in data engineering technologies\n",
      "       2. Preparing for future challenges and opportunities\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 24.2s\n",
    "# 34.9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you’ve successfully produced a hierarchical article outline, but how could you parse the string into structured data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3.1 Parsing a hierierarchical list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headings:\n",
      "\n",
      "* Introduction\n",
      "* Efficient Data Management\n",
      "* Conclusion\n",
      "\n",
      "Subheadings:\n",
      "\n",
      "* Explanation of data engineering\n",
      "* Importance of data engineering in today’s data-driven world\n",
      "* Definition of data management\n",
      "* How data engineering helps in efficient data management.\n",
      "* Importance of Data Engineering in the modern business world\n",
      "* Future of Data Engineering and its impact on the data ecosystem\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# openai_result = generate_article_outline(prompt)\n",
    "\n",
    "openai_result = \"\"\"\n",
    "* Introduction\n",
    "    a. Explanation of data engineering\n",
    "    b. Importance of data engineering in today’s data-driven world\n",
    "* Efficient Data Management\n",
    "    a. Definition of data management\n",
    "    b. How data engineering helps in efficient data management.\n",
    "* Conclusion\n",
    "    a. Importance of Data Engineering in the modern business world\n",
    "    b. Future of Data Engineering and its impact on the data ecosystem\n",
    "\"\"\"\n",
    "\n",
    "# Regular expression patterns\n",
    "heading_pattern = r\"\\* (.+)\"\n",
    "subheading_pattern = r\"\\s+[a-z]\\. (.+)\"\n",
    "\n",
    "# Extract headings and subheadings\n",
    "headings = re.findall(heading_pattern, openai_result)\n",
    "subheadings = re.findall(subheading_pattern, openai_result)\n",
    "\n",
    "# Print results\n",
    "print(\"Headings:\\n\")\n",
    "for heading in headings:\n",
    "    print(f\"* {heading}\")\n",
    "\n",
    "print(\"\\nSubheadings:\\n\")\n",
    "for subheading in subheadings:\n",
    "    print(f\"* {subheading}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3.2 Parsing a hierarchical list into a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Introduction': ['a. Explanation of data engineering',\n",
       "  'b. Importance of data engineering in today’s data-driven world'],\n",
       " 'Efficient Data Management': ['a. Definition of data management',\n",
       "  'b. How data engineering helps in efficient data management.',\n",
       "  'c. Why data engineering is important for data management'],\n",
       " 'Conclusion': ['a. Importance of Data Engineering in the modern business world',\n",
       "  'b. Future of Data Engineering and its impact on the data ecosystem']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "openai_result = \"\"\"\n",
    "* Introduction\n",
    "  a. Explanation of data engineering\n",
    "  b. Importance of data engineering in today’s data-driven world\n",
    "* Efficient Data Management\n",
    "    a. Definition of data management\n",
    "    b. How data engineering helps in efficient data management.\n",
    "    c. Why data engineering is important for data management\n",
    "* Conclusion\n",
    "    a. Importance of Data Engineering in the modern business world\n",
    "    b. Future of Data Engineering and its impact on the data ecosystem\n",
    "\"\"\"\n",
    "\n",
    "section_regex = re.compile(r\"\\* (.+)\")\n",
    "subsection_regex = re.compile(r\"\\s*([a-z]\\..+)\")\n",
    "\n",
    "result_dict = {}\n",
    "current_section = None\n",
    "\n",
    "for line in openai_result.split(\"\\n\"):\n",
    "    section_match = section_regex.match(line)\n",
    "    subsection_match = subsection_regex.match(line)\n",
    "\n",
    "    if section_match:\n",
    "        current_section = section_match.group(1)\n",
    "        result_dict[current_section] = []\n",
    "    elif subsection_match and current_section is not None:\n",
    "        result_dict[current_section].append(subsection_match.group(1))\n",
    "\n",
    "#print(result_dict)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Avoid using Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Compose a very detailed article outline on \"The benefits of learning code\" with a JSON payload structure that highlights key points.\n",
    "\n",
    "Only return valid JSON.\n",
    "\n",
    "Here is an example of the JSON structure:\n",
    "```{\n",
    "    \"Introduction\": [\n",
    "        \"a. Explanation of data engineering\",\n",
    "        \"b. Importance of data engineering in today’s data-driven world\"],\n",
    "    \"Efficient Data Management\": [\n",
    "        \"a. Definition of data management\",\n",
    "        \"b. How data engineering helps in efficient data management.\"],\n",
    "    \"Conclusion\": [\n",
    "        \"a. Importance of Data Engineering in the modern business world\",\n",
    "        \"b. Future of Data Engineering and its impact on the data ecosystem\"]\n",
    "} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Introduction\": [\n",
      "        \"a. Explanation of what coding is and why it's important\",\n",
      "        \"b. Overview of the increasing demand for coders in various industries\"\n",
      "    ],\n",
      "    \"Enhanced Problem-Solving Skills\": [\n",
      "        \"a. Development of logical thinking through programming challenges\",\n",
      "        \"b. Application of problem-solving skills to real-world scenarios beyond coding\",\n",
      "        \"c. Improved analytical capabilities and decision-making processes\"\n",
      "    ],\n",
      "    \"Career Opportunities and Advancement\": [\n",
      "        \"a. Broad range of career options in software development, data science, web design, etc.\",\n",
      "        \"b. High demand for skilled coders leading to better job prospects and higher salaries\",\n",
      "        \"c. Continuous learning and adaptation necessary in the rapidly evolving tech industry\"\n",
      "    ],\n",
      "    \"Personal Creativity and Innovation\": [\n",
      "        \"a. Freedom to create unique software applications or improve existing ones\",\n",
      "        \"b. Collaboration with other developers for innovative projects\",\n",
      "        \"c. Personal satisfaction from bringing ideas to life through code\"\n",
      "    ],\n",
      "    \"Improved Communication Skills\": [\n",
      "        \"a. Clear and structured thinking required in coding leading to better communication\",\n",
      "        \"b. Understanding how technology impacts daily tasks and explaining it to others\",\n",
      "        \"c. Enhanced teamwork during collaborative projects involving programming\"\n",
      "    ],\n",
      "    \"Adaptability to New Technologies\": [\n",
      "        \"a. Continuous learning curve that keeps coders updated with the latest trends\",\n",
      "        \"b. Flexibility in adopting new languages or frameworks as they evolve\",\n",
      "        \"c. Importance of adaptability in a field driven by innovation and change\"\n",
      "    ],\n",
      "    \"Increased Productivity through Automation\": [\n",
      "        \"a. Ability to automate repetitive tasks using scripts and programs\",\n",
      "        \"b. Time savings achieved from automating manual processes\",\n",
      "        \"c. Focus on more complex problem solving due to automation handling the basics\"\n",
      "    ],\n",
      "    \"Conclusion\": [\n",
      "        \"a. Summary of key benefits of learning how to code\",\n",
      "        \"b. Encouragement for individuals to embrace coding as a valuable skill in today’s digital world\",\n",
      "        \"c. Future outlook on coding education and its impact on personal development and job markets\"\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 17.1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine how we can parse JSON output with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Introduction': ['a. Overview of coding and programming languages',\n",
       "  \"b. Importance of coding in today's technology-driven world\"],\n",
       " 'Conclusion': ['a. Recap of the benefits of learning code',\n",
       "  'b. The ongoing importance of coding skills in the modern world']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# openai_json_result = generate_article_outline(prompt)\n",
    "\n",
    "openai_json_result = \"\"\"\n",
    "{\n",
    "    \"Introduction\": [\n",
    "        \"a. Overview of coding and programming languages\",\n",
    "        \"b. Importance of coding in today's technology-driven world\"],\n",
    "    \"Conclusion\": [\n",
    "        \"a. Recap of the benefits of learning code\",\n",
    "        \"b. The ongoing importance of coding skills in the modern world\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "parsed_json_payload = json.loads(openai_json_result)\n",
    "# print(parsed_json_payload)\n",
    "parsed_json_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Return valid `.yml` for 5 apple slices, and 2 dozen eggs.\n",
    "\n",
    "- Below you'll find the current yaml schema.\n",
    "- Please only use the schema below and if you are unsure, then return `Unsure`.\n",
    "\n",
    "```\n",
    "- item: Apple Slices\n",
    "  quantity: 5\n",
    "  unit: pieces\n",
    "- item: Milk\n",
    "  quantity: 1\n",
    "  unit: gallon\n",
    "- item: Bread\n",
    "  quantity: 2\n",
    "  unit: loaves\n",
    "- item: Eggs\n",
    "  quantity: 1\n",
    "  unit: dozen\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided schema, here is the valid `.yml` for 5 apple slices and 2 dozen eggs:\n",
      "\n",
      "```\n",
      "- item: Apple Slices\n",
      "  quantity: 5\n",
      "  unit: pieces\n",
      "- item: Eggs\n",
      "  quantity: 2\n",
      "  unit: dozen\n",
      "```\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 2.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering YAML payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 is valid\n",
      "Response 2 is valid\n",
      "Response 3 is invalid: Response is not a list\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "class InvalidResponse(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidItemType(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidItemKeys(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidItemName(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidItemQuantity(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidItemUnit(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Provided schema\n",
    "schema = \"\"\"\n",
    "- item: Apple Slices\n",
    "  quantity: 5\n",
    "  unit: pieces\n",
    "- item: Milk\n",
    "  quantity: 1\n",
    "  unit: gallon\n",
    "- item: Bread\n",
    "  quantity: 2\n",
    "  unit: loaves\n",
    "- item: Eggs\n",
    "  quantity: 1\n",
    "  unit: dozen\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def validate_response(response, schema):\n",
    "    # Parse the schema\n",
    "    schema_parsed = yaml.safe_load(schema)\n",
    "\n",
    "    # Check if the response is a list\n",
    "    if not isinstance(response, list):\n",
    "        raise InvalidResponse(\"Response is not a list\")\n",
    "\n",
    "    # Check if each item in the list is a dictionary\n",
    "    for item in response:\n",
    "        if not isinstance(item, dict):\n",
    "            raise InvalidItemType(\"Response item is not a dictionary\")\n",
    "\n",
    "        # Check if each dictionary has the keys \"item\", \"quantity\", and \"unit\"\n",
    "        if not all(key in item for key in (\"item\", \"quantity\", \"unit\")):\n",
    "            raise InvalidItemKeys(\"Response item does not have the correct keys\")\n",
    "\n",
    "        # Check if the values associated with each key are the correct type\n",
    "        if not isinstance(item[\"item\"], str):\n",
    "            raise InvalidItemName(\"Response item name is not a string\")\n",
    "        if not isinstance(item[\"quantity\"], int):\n",
    "            raise InvalidItemQuantity(\"Response item quantity is not an integer\")\n",
    "        if not isinstance(item[\"unit\"], str):\n",
    "            raise InvalidItemUnit(\"Response item unit is not a string\")\n",
    "\n",
    "        # Check if the values associated with each key are the correct value\n",
    "        if item[\"item\"] not in [x[\"item\"] for x in schema_parsed]:\n",
    "            raise InvalidItemName(\"Response item name is not in schema\")\n",
    "        if item[\"quantity\"] > 10:\n",
    "            raise InvalidItemQuantity(\"Response item quantity is greater than 10\")\n",
    "        if item[\"unit\"] not in [\"pieces\", \"dozen\"]:\n",
    "            raise InvalidItemUnit(\"Response item unit is not pieces or dozen\")\n",
    "\n",
    "\n",
    "# Fake responses\n",
    "fake_response_1 = \"\"\"\n",
    "- item: Apple Slices\n",
    "  quantity: 5\n",
    "  unit: pieces\n",
    "- item: Eggs\n",
    "  quantity: 2\n",
    "  unit: dozen\n",
    "\"\"\"\n",
    "\n",
    "fake_response_2 = \"\"\"\n",
    "# Updated yaml list\n",
    "- item: Apple Slices\n",
    "  quantity: 5\n",
    "  unit: pieces\n",
    "\"\"\"\n",
    "\n",
    "fake_response_3 = \"\"\"Unmatched\"\"\"\n",
    "\n",
    "# Parse the fake responses\n",
    "response_1_parsed = yaml.safe_load(fake_response_1)\n",
    "response_2_parsed = yaml.safe_load(fake_response_2)\n",
    "response_3_parsed = yaml.safe_load(fake_response_3)\n",
    "\n",
    "# Validate the responses against the schema\n",
    "try:\n",
    "    validate_response(response_1_parsed, schema)\n",
    "    print(\"Response 1 is valid\")\n",
    "except Exception as e:\n",
    "    print(\"Response 1 is invalid:\", str(e))\n",
    "\n",
    "try:\n",
    "    validate_response(response_2_parsed, schema)\n",
    "    print(\"Response 2 is valid\")\n",
    "except Exception as e:\n",
    "    print(\"Response 2 is invalid:\", str(e))\n",
    "\n",
    "try:\n",
    "    validate_response(response_3_parsed, schema)\n",
    "    print(\"Response 3 is valid\")\n",
    "except Exception as e:\n",
    "    print(\"Response 3 is invalid:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diverse Format Generation with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to restart things from here just so that I do not have to run anything above ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Point to the local server ... last guy wins.\n",
    "lmstudio = \"http://localhost:1234/v1\"\n",
    "\n",
    "client = OpenAI(base_url=lmstudio, api_key=\"lm-studio\")\n",
    "\n",
    "model = \"qwen2.5-14b-instruct\" # lmstudio-community/Qwen2.5-14B-Instruct-GGUF : Qwen2.5-14B-Instruct-Q4_K_M.gguf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the default temperature setting in OpenAI’s fine-tuned models is around 0.7. Temperature controls the randomness of the generated text. Lower temperatures result in more deterministic output, while higher temperatures lead to more diversity and randomness in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        model = model ,\n",
    "        temperature=0.0, # Setting the temperature to 0 ensures that the model will always choose the most likely next word, leading to more deterministic and less random output.\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Create a flowchart diagram in mermaid syntax showing a simple food ordering\n",
    "process that starts with \"Choose food\" and ends with \"Pay for meal.\"\n",
    "Include steps for \"Add food to cart\" and \"Confirm cart.\"`\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is the Mermaid syntax for a flowchart depicting a simple food ordering process:\n",
      "\n",
      "```mermaid\n",
      "flowchart TD\n",
      "\n",
      "    A[Choose food] --> B{Do you want to add more?}\n",
      "    B -- Yes --> C[Add food to cart]\n",
      "    C --> D{Confirm cart?}\n",
      "    D -- No --> B\n",
      "    D -- Yes --> E[Pay for meal]\n",
      "\n",
      "    style A fill:#f96,stroke:#333,stroke-width:4px\n",
      "    style E fill:#6c6,stroke:#333,stroke-width:4px\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **A**: The process starts with \"Choose food.\"\n",
      "- **B**: After choosing the food, there's a decision point asking if you want to add more items.\n",
      "  - If yes, it goes back to adding more food to the cart (`C`).\n",
      "  - If no, it proceeds to confirm the cart (`D`).\n",
      "- **C**: The selected food is added to the cart.\n",
      "- **D**: There's a confirmation step asking if you want to proceed with the current items in the cart.\n",
      "  - If not confirmed, it loops back to adding more food or confirming again.\n",
      "  - If confirmed, it proceeds to paying for the meal (`E`).\n",
      "- **E**: The process ends by paying for the meal.\n",
      "\n",
      "The `style` commands are used to highlight the start and end points of the flowchart.\n"
     ]
    }
   ],
   "source": [
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 49.8 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is the Mermaid syntax for a flowchart depicting a simple food ordering process:\n",
      "\n",
      "```mermaid\n",
      "flowchart TD\n",
      "\n",
      "    A[Choose food] --> B{Do you want to add more?}\n",
      "    B -->|Yes| C[Add food to cart]\n",
      "    C --> D[Confirm cart]\n",
      "    D --> E{Proceed to checkout?}\n",
      "    E -->|Yes| F[Pay for meal]\n",
      "    E -->|No| G[Remove items from cart]\n",
      "    G --> H[Confirm cart]\n",
      "    H --> I{Proceed to checkout?}\n",
      "    I -->|Yes| F\n",
      "    I -->|No| B\n",
      "\n",
      "    B -->|No| D\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **A (Choose food)**: The process starts with the user choosing their desired food items.\n",
      "2. **B (Do you want to add more?)**: After selecting an item, the system asks if the user wants to add more items to their order.\n",
      "3. **C (Add food to cart)**: If the user chooses \"Yes,\" they can add additional items to their cart.\n",
      "4. **D (Confirm cart)**: The user confirms the items in their cart before proceeding further.\n",
      "5. **E (Proceed to checkout?)**: After confirming the cart, the system asks if the user is ready to proceed to checkout.\n",
      "6. **F (Pay for meal)**: If the user chooses \"Yes,\" they pay for their order and complete the process.\n",
      "7. **G (Remove items from cart)**: If the user chooses \"No\" at step E, they can remove items from their cart.\n",
      "8. **H (Confirm cart)**: After removing or modifying items in the cart, the user confirms the updated cart.\n",
      "9. **I (Proceed to checkout?)**: The system again asks if the user is ready to proceed to checkout.\n",
      "\n",
      "This flowchart ensures that users have multiple opportunities to modify their order before finalizing it and paying for their meal.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 1m 7.5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mock CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Generate a sample CSV data for five students with the following fields:\n",
    "name, age, grade.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is an example of how you can structure a CSV file containing information about five students:\n",
      "\n",
      "```csv\n",
      "name,age,grade\n",
      "Alice Smith,15,9\n",
      "Bob Johnson,16,10\n",
      "Charlie Brown,14,8\n",
      "David Lee,17,12\n",
      "Eve Wilson,15,9\n",
      "```\n",
      "\n",
      "Here's a breakdown of the data:\n",
      "- Each line represents one student.\n",
      "- The first line contains the column headers: `name`, `age`, and `grade`.\n",
      "- Subsequent lines contain the actual data for each student.\n",
      "\n",
      "You can save this content in a file with a `.csv` extension to use it as a CSV file.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain it like I'm five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Explain the following text as if I was 5 years old. Explain it like I'm 5.\n",
    "Text: This is a review regarding different types of cancer treatments.\n",
    "We aimed at analyzing the tumor microenvironment and the recent trends\n",
    "for the therapeutic applications and effectiveness for several kinds\n",
    "of cancers. Traditionally the cancer treatment was based on the\n",
    "neoplastic cells.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, little one! Let's talk about how doctors help people who are sick with something called \"cancer.\"\n",
      "\n",
      "Imagine you have a big coloring book where some pages have spots that shouldn't be there - those spots are like cancer in our bodies. Doctors used to just look at the spots and try to make them go away.\n",
      "\n",
      "But now, they're doing something new! They're looking at the whole page of your coloring book, not just the spots. They want to know about all the colors around the spots too, because sometimes those other colors can help or hurt the spots.\n",
      "\n",
      "The doctors are trying to find better ways to make the bad spots go away by understanding everything on the page, not just the spots themselves. This helps them figure out which crayons (or medicines) work best for different kinds of coloring books (different types of cancer).\n",
      "\n",
      "So instead of just looking at one thing, they're looking at lots of things together to help people feel better!\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ask for Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Should I use MongoDB or PostgreSQL for my project?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing between MongoDB and PostgreSQL depends on the specific requirements of your project, such as data structure, performance needs, scalability, and development team expertise. Here’s an overview to help you decide:\n",
      "\n",
      "### MongoDB (NoSQL Document Database)\n",
      "**Pros:**\n",
      "1. **Flexible Schema:** Documents can have varying structures, making it easy to handle evolving data models.\n",
      "2. **Scalability:** Horizontal scaling is straightforward with sharding and replication.\n",
      "3. **Performance:** Good for high write throughput and complex queries involving large datasets.\n",
      "4. **Aggregation Framework:** Powerful tool for querying and analyzing data.\n",
      "\n",
      "**Cons:**\n",
      "1. **ACID Compliance:** Not fully ACID-compliant (though MongoDB 4.0+ has improved this).\n",
      "2. **Learning Curve:** If your team is more familiar with SQL, there might be a learning curve.\n",
      "3. **Data Integrity:** Less robust in enforcing referential integrity compared to relational databases.\n",
      "\n",
      "### PostgreSQL (Relational Database)\n",
      "**Pros:**\n",
      "1. **ACID Compliance:** Fully ACID-compliant, ensuring data consistency and reliability.\n",
      "2. **Rich Feature Set:** Supports advanced features like JSONB, full-text search, and GIS capabilities.\n",
      "3. **SQL Standard Adherence:** Familiar to developers with SQL background.\n",
      "4. **Data Integrity:** Strong support for referential integrity through foreign keys.\n",
      "\n",
      "**Cons:**\n",
      "1. **Fixed Schema:** Requires defining tables and columns upfront, which can be inflexible for evolving data models.\n",
      "2. **Scalability Challenges:** Vertical scaling is easier than horizontal scaling (though it supports partitioning).\n",
      "\n",
      "### Considerations\n",
      "- **Data Model Complexity**: If your project involves complex relationships and requires strict schema definitions, PostgreSQL might be better suited.\n",
      "- **Performance Needs**: MongoDB can handle high write throughput more efficiently due to its document-oriented nature.\n",
      "- **Team Expertise**: If your team is already familiar with SQL and relational databases, PostgreSQL will likely offer a smoother development process.\n",
      "\n",
      "### Example Scenarios\n",
      "1. **Web Applications with Complex User Data**: PostgreSQL might be better if you need robust data integrity and complex relationships (e.g., e-commerce platforms).\n",
      "2. **Real-time Analytics and IoT Data**: MongoDB could be more appropriate for handling large volumes of unstructured or semi-structured data in real-time.\n",
      "3. **Content Management Systems**: If your project involves managing a lot of content with varying structures, MongoDB’s flexible schema might be advantageous.\n",
      "\n",
      "### Conclusion\n",
      "If you prioritize flexibility, scalability, and performance over strict schema definitions and ACID compliance, MongoDB could be the better choice. Conversely, if you need robust data integrity, complex queries, and are comfortable with SQL, PostgreSQL would likely serve your project well.\n",
      "\n",
      "Consider prototyping both options to see which one fits best with your specific requirements and team dynamics.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 1m 37.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Should I use MongoDB or PostgreSQL for my project?\n",
    "Provide a list of requirements that would help you to make an informed\n",
    "and high-quality decision about which database solution I should choose?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine whether MongoDB (a NoSQL document-oriented database) or PostgreSQL (an SQL relational database) is the right choice for your project, it's important to consider several key factors. Here’s a list of requirements and considerations that will help you make an informed decision:\n",
      "\n",
      "### 1. **Data Model Complexity**\n",
      "   - **Document-Oriented vs Relational Data Models:**\n",
      "     - Does your data have complex hierarchical structures or nested documents?\n",
      "     - Do you need flexible schema design with dynamic fields?\n",
      "\n",
      "### 2. **Scalability Requirements**\n",
      "   - **Horizontal Scaling (Sharding):**\n",
      "     - Will the database need to scale horizontally by distributing data across multiple servers?\n",
      "     - Are there specific requirements for handling large volumes of unstructured or semi-structured data?\n",
      "\n",
      "### 3. **Performance and Speed**\n",
      "   - **Query Performance:**\n",
      "     - What are your performance expectations in terms of read/write speeds, latency, and throughput?\n",
      "     - Do you need real-time analytics capabilities?\n",
      "\n",
      "### 4. **Data Integrity and ACID Compliance**\n",
      "   - **Transaction Support:**\n",
      "     - Are transactions (ACID properties) critical for maintaining data integrity?\n",
      "     - Does the application require complex joins, subqueries, or advanced SQL features?\n",
      "\n",
      "### 5. **Development Environment and Language Support**\n",
      "   - **Programming Languages and Drivers:**\n",
      "     - What programming languages will you be using to interact with the database?\n",
      "     - Are there specific drivers or libraries that are more mature for your chosen language?\n",
      "\n",
      "### 6. **Community and Ecosystem**\n",
      "   - **Support and Community Resources:**\n",
      "     - How active is the community around each technology?\n",
      "     - Are there extensive documentation, tutorials, and third-party tools available?\n",
      "\n",
      "### 7. **Cost Considerations**\n",
      "   - **Open Source vs Commercial Support:**\n",
      "     - Is cost a significant factor? (PostgreSQL has both open-source and commercial editions)\n",
      "     - Do you need enterprise-level support or advanced features that come with a price tag?\n",
      "\n",
      "### 8. **Backup, Recovery, and Maintenance**\n",
      "   - **Data Backup and Restore:**\n",
      "     - What are your requirements for data backup, recovery, and disaster recovery?\n",
      "     - How easy is it to perform these tasks in each database system?\n",
      "\n",
      "### 9. **Integration Capabilities**\n",
      "   - **Third-Party Integrations:**\n",
      "     - Do you need to integrate with other systems or services (e.g., cloud storage, analytics tools)?\n",
      "     - Are there existing integrations available for MongoDB and PostgreSQL that meet your needs?\n",
      "\n",
      "### 10. **Security Requirements**\n",
      "   - **Data Security and Compliance:**\n",
      "     - What are the security requirements of your application?\n",
      "     - Do you need to comply with specific regulations (e.g., GDPR, HIPAA)?\n",
      "\n",
      "### 11. **Development Team Expertise**\n",
      "   - **Team Familiarity:**\n",
      "     - Does your team have more experience with SQL or NoSQL databases?\n",
      "     - What is the learning curve for each technology?\n",
      "\n",
      "### 12. **Future-Proofing and Long-Term Vision**\n",
      "   - **Scalability and Flexibility:**\n",
      "     - How likely are your data models to change over time?\n",
      "     - Do you need a database that can adapt to evolving requirements without significant rework?\n",
      "\n",
      "By carefully considering these factors, you will be better equipped to choose the most suitable database solution for your project. If you provide more specific details about your project's needs and constraints, I can offer more tailored advice.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 2m 0.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Should I use MongoDB or PostgreSQL for my project?\n",
    "Context:\n",
    "- Data Structure: Highly unstructured data with varying document formats\n",
    "and no fixed schema. Scalability: Project requires the ability to handle\n",
    "massive amounts of data and distribute it across multiple servers.\n",
    "- ACID Compliance: Strong data consistency and integrity are crucial for\n",
    "the project's financial transactions.\n",
    "- Querying Capabilities: Complex geospatial queries and aggregations on\n",
    "location-based data.\n",
    "Community and Ecosystem: Active community with numerous third-party\n",
    "libraries and tools specifically tailored for the project's industry.\n",
    "- Data Integrity and Constraints: Enforcing strict foreign key\n",
    "relationships and complex data validation rules.\n",
    "- Transactions and Concurrency: Requires handling high levels of\n",
    "concurrent read and write operations while maintaining data consistency.\n",
    "- Maturity and Stability: Prioritizing a well-established and extensively\n",
    "tested database for long-term stability.\n",
    "- Development and Operational Ease: Agile development approach with a need\n",
    "for rapid prototyping and iterative schema design.\n",
    "- Cost: Budget constraints necessitate using an open-source solution with\n",
    "no additional licensing or support costs.\n",
    "If you need more context, please specify what would help you to make\n",
    "a better decision.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the detailed requirements for your project, here's a breakdown of how MongoDB and PostgreSQL compare based on each criterion:\n",
      "\n",
      "### Data Structure:\n",
      "- **MongoDB**: Highly unstructured data with varying document formats fits well into MongoDB’s schema-less design.\n",
      "- **PostgreSQL**: Can handle complex schemas but might require more upfront planning.\n",
      "\n",
      "### Scalability:\n",
      "- **MongoDB**: Known for its horizontal scalability, allowing easy distribution of data across multiple servers.\n",
      "- **PostgreSQL**: Also scalable but typically requires more configuration and management to distribute data effectively.\n",
      "\n",
      "### ACID Compliance:\n",
      "- **MongoDB**: MongoDB 4.0+ supports multi-document transactions (ACID-compliant), but it's relatively new compared to PostgreSQL.\n",
      "- **PostgreSQL**: Strongly adheres to ACID principles, making it a reliable choice for financial transactions.\n",
      "\n",
      "### Querying Capabilities:\n",
      "- **MongoDB**: Excellent support for geospatial queries and aggregations through its native indexing and query capabilities.\n",
      "- **PostgreSQL**: Also supports advanced querying with extensions like PostGIS for geospatial data.\n",
      "\n",
      "### Community and Ecosystem:\n",
      "- **MongoDB**: Large community, especially in modern web development contexts.\n",
      "- **PostgreSQL**: Extensive community and a wide range of third-party tools and libraries across various industries.\n",
      "\n",
      "### Data Integrity and Constraints:\n",
      "- **MongoDB**: Limited support for foreign key relationships and complex constraints compared to PostgreSQL.\n",
      "- **PostgreSQL**: Strong support for enforcing strict data integrity rules, including foreign keys and complex validation rules.\n",
      "\n",
      "### Transactions and Concurrency:\n",
      "- **MongoDB**: Supports multi-document transactions but might have limitations in handling high concurrency levels compared to PostgreSQL.\n",
      "- **PostgreSQL**: Robust transaction management and strong performance under concurrent operations.\n",
      "\n",
      "### Maturity and Stability:\n",
      "- **MongoDB**: Relatively newer, with rapid development cycles. However, it has matured significantly over the years.\n",
      "- **PostgreSQL**: Well-established, extensively tested, and highly stable database system.\n",
      "\n",
      "### Development and Operational Ease:\n",
      "- **MongoDB**: Agile-friendly due to its schema-less nature, making it easier for iterative design and prototyping.\n",
      "- **PostgreSQL**: Requires more upfront planning but offers robust development tools and mature operational practices.\n",
      "\n",
      "### Cost:\n",
      "- **MongoDB**: Open-source with no licensing costs, though managed services can incur additional expenses.\n",
      "- **PostgreSQL**: Completely open-source without any licensing fees or support costs.\n",
      "\n",
      "### Recommendation:\n",
      "\n",
      "Given your project's requirements, PostgreSQL seems to be the better fit due to its strong adherence to ACID principles, robust data integrity features, and extensive community support. While MongoDB is highly scalable and suitable for unstructured data, it might fall short in terms of transactional consistency and complex data validation rules required by financial transactions.\n",
      "\n",
      "However, if you prioritize rapid prototyping and agile development with a need for schema flexibility, MongoDB could still be considered, especially since its multi-document ACID support has improved significantly. You may also consider hybrid approaches where PostgreSQL handles critical financial operations while MongoDB manages less structured data or serves as a secondary database for analytics.\n",
      "\n",
      "Ultimately, the decision depends on balancing your project's specific needs and constraints. If you need further customization or have additional requirements not covered here, please provide more context so I can offer more tailored advice.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 1m 51.9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Style Unbundling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Analyze the following text and identify core features that will allow\n",
    "further documents to imitate the same style, consistency, and formatting\n",
    "as the document below.\n",
    "Provide all of the features as a style writing guide that will be used\n",
    "for future documents.\n",
    "Analyze the following text:\n",
    "Artificial intelligence is rapidly transforming the world around us,\n",
    "opening up new possibilities and revolutionizing industries. From\n",
    "health care to entertainment, AI is making our lives better and more\n",
    "convenient in countless ways. However, with great power comes great\n",
    "responsibility. We must ensure that AI technologies are developed and\n",
    "deployed ethically and responsibly to protect our privacy and uphold our\n",
    "values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To imitate the style, consistency, and formatting of the given text, here is a detailed guide for future documents:\n",
      "\n",
      "### Style Writing Guide\n",
      "\n",
      "#### 1. **Tone**\n",
      "   - The tone should be informative yet engaging.\n",
      "   - Use a balanced perspective that acknowledges both the benefits and potential risks of AI.\n",
      "\n",
      "#### 2. **Structure**\n",
      "   - Start with an introductory sentence or two to set the context.\n",
      "   - Follow with supporting sentences that elaborate on specific examples or areas where AI is making an impact.\n",
      "   - Conclude with a statement about ethical considerations and responsibilities.\n",
      "\n",
      "#### 3. **Sentence Structure**\n",
      "   - Use a mix of short and long sentences for readability and emphasis.\n",
      "   - Begin sentences with strong, declarative statements to capture attention.\n",
      "   - Include transitional phrases (e.g., \"From,\" \"However\") to maintain flow and coherence.\n",
      "\n",
      "#### 4. **Vocabulary**\n",
      "   - Employ clear and concise language.\n",
      "   - Use technical terms related to AI when necessary but ensure they are explained or familiar to the audience.\n",
      "   - Avoid jargon unless it is commonly understood in the context of the document.\n",
      "\n",
      "#### 5. **Themes**\n",
      "   - Highlight the transformative nature of AI across various industries (e.g., healthcare, entertainment).\n",
      "   - Emphasize both positive impacts and ethical concerns related to privacy and values.\n",
      "\n",
      "#### 6. **Formatting**\n",
      "   - Use bullet points or numbered lists sparingly for emphasis on key points.\n",
      "   - Maintain consistent paragraph breaks to improve readability.\n",
      "   - Ensure proper punctuation and grammar throughout the document.\n",
      "\n",
      "### Example of a New Document Following This Guide\n",
      "\n",
      "**Artificial intelligence is rapidly advancing in various sectors, bringing about significant changes. From enhancing medical diagnostics to revolutionizing entertainment experiences, AI technologies are making our lives more convenient and efficient. However, as these advancements continue, it becomes crucial to address the ethical implications and ensure that privacy rights and societal values are protected during the development and deployment of AI systems.**\n",
      "\n",
      "By following this guide, future documents can maintain a consistent tone, structure, and style similar to the provided text while effectively communicating about AI's impact and responsibilities.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "\n",
    "# 1m 13.9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Specific Textual Features with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt  = \"\"\"Analyze the following text to identify and list the entities mentioned:\n",
    "Artificial intelligence is rapidly transforming the world around us,\n",
    "opening up new possibilities and revolutionizing industries. From\n",
    "health care to entertainment, AI is making our lives better and more\n",
    "convenient in countless ways. However, with great power comes great\n",
    "responsibility. We must ensure that AI technologies are developed\n",
    "and deployed ethically and responsibly to protect our privacy and\n",
    "uphold our values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text mentions the following entities:\n",
      "\n",
      "1. **Artificial intelligence (AI)** - The primary subject of discussion in the text.\n",
      "2. **Health care** - One of the industries mentioned as being impacted by AI.\n",
      "3. **Entertainment** - Another industry mentioned as being influenced by AI.\n",
      "\n",
      "There are no specific named individuals, organizations, or locations mentioned in this passage.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summarize the following text:\n",
    "Whereas the party of the first part, hereinafter referred to as the\n",
    "\"Purchaser,\" and the party of the second part, hereinafter referred to\n",
    "as the \"Vendor,\" being fully cognizant of their respective legal\n",
    "obligations and responsibilities pursuant to the applicable statutory\n",
    "provisions and common law doctrines, have duly entered into a legally\n",
    "binding agreement, hereinafter referred to as the \"Agreement,\" for the\n",
    "purpose of effectuating a transaction involving the transfer of goods,\n",
    "hereinafter referred to as the \"Goods,\" between the Purchaser and the\n",
    "Vendor, subject to the terms and conditions set forth herein, the Parties\n",
    "do hereby solemnly acknowledge and affirm the following: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is an introductory legal statement in which:\n",
      "\n",
      "- The \"Purchaser\" and \"Vendor\" agree to a binding contract.\n",
      "- They are aware of their legal obligations under relevant laws.\n",
      "- The agreement is for transferring goods from Vendor to Purchaser.\n",
      "- The terms and conditions of the transaction are outlined.\n",
      "\n",
      "In essence, it establishes that both parties acknowledge and accept the legal agreement for the sale of goods.\n"
     ]
    }
   ],
   "source": [
    " # Get a response from the model\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Given Context Window Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe4gai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
