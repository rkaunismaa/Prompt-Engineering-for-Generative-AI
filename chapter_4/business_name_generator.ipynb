{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friday, December 20, 2024\n",
    "\n",
    "This all runs in one pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliberately set the OPENAI_API_KEY to an invalid value to ensure that the code is not using it.\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"Nope!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a creative consultant brainstorming names for businesses.\n",
    "\n",
    "You must follow the following principles:\n",
    "{principles}\n",
    "\n",
    "Please generate a numerical list of 5 catchy names for a start-up in the {industry} industry that deals with {context}?\n",
    "\n",
    "Here is an example of the format:\n",
    "1. Name1\n",
    "2. Name2\n",
    "3. Name3\n",
    "4. Name4\n",
    "5. Name5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatOpenAI()\n",
    "# Point to the local server ... last guy wins.\n",
    "lmstudio = \"http://localhost:1234/v1\"\n",
    "model = \"qwen2.5-14b-instruct@q8_0\" # lmstudio-community/Qwen2.5-14B-Instruct-GGUF :  Qwen2.5-14B-Instruct-Q4_K_M.gguf\n",
    "\n",
    "model = ChatOpenAI(base_url=lmstudio, model=model, api_key=\"LMStudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the default temperature if we do not specify it?\n",
    "model.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MedSumAI\n",
      "2. DocDigest\n",
      "3. QuickChartIQ\n",
      "4. HealthSnapshots\n",
      "5. PatientPulseAI\n"
     ]
    }
   ],
   "source": [
    "# the call to the model is made here ...\n",
    "result = chain.invoke({\n",
    "    \"industry\": \"medical\",\n",
    "    \"context\":\"creating AI solutions by automatically summarizing patient records\",\n",
    "    \"principles\":'''1. Each name should be short and easy to remember. 2. Each name should be easy to pronounce.\n",
    "    3. Each name should be unique and not already taken by another company.'''\n",
    "})\n",
    "\n",
    "print(result.content)\n",
    "\n",
    "# repo sample output\n",
    "# 1. SummaAI\n",
    "# 2. MedAI\n",
    "# 3. RecapMed\n",
    "# 4. SmartSum\n",
    "# 5. DocuSumm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to do this is to use the ChatPromptTemplate directly with `.format()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = chat_prompt.format(\n",
    "    industry=\"medical\",\n",
    "    context=\"creating AI solutions by automatically summarizing patient records\",\n",
    "    principles=\"1. Each name should be short and easy to remember. 2. Each name should be easy to pronounce. 3. Each name should be unique and not already taken by another company.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MedSumAI\n",
      "2. PatientSnap\n",
      "3. HealthScribe\n",
      "4. DocDigest\n",
      "5. QuickChartAI\n"
     ]
    }
   ],
   "source": [
    "# Generate names\n",
    "business_names = model.invoke(formatted_prompt)\n",
    "print(business_names.content)\n",
    "\n",
    "# repo sample output\n",
    "# 1. MedSumAI\n",
    "# 2. RecordEase\n",
    "# 3. Summarix\n",
    "# 4. AutoMedSum\n",
    "# 5. DocuSumm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe4gai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
